{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4d6a06c-db25-412f-aea1-608831ddad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"output.csv\")\n",
    "\n",
    "df['Keywords'] = df['Keywords'].str.split(',')\n",
    "df['GroundTruth Keywords']=df['GroundTruth Keywords'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ffc803d-dcf0-4806-9141-9597b6058b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Paraphrased Post</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Take Aways</th>\n",
       "      <th>Highlights</th>\n",
       "      <th>GroundTruth Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/posts/sahibpreetsingh...</td>\n",
       "      <td>Hello LLM Enthusiasts,\\nStarting a New Day wit...</td>\n",
       "      <td>[Semantic Chunking, Retrieval, RAG]</td>\n",
       "      <td>Chunking involves dividing a document into sma...</td>\n",
       "      <td>How can we break down intricate user inquiries...</td>\n",
       "      <td>[Semantic Chunking, Retrieval, RAG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/posts/sahibpreetsingh...</td>\n",
       "      <td>Hello, ùóüùóüùó† Enthusiasts, Get Ready for an Adven...</td>\n",
       "      <td>[LLM Enthusiasts, Judge, LLM-generated answers]</td>\n",
       "      <td>LLMs serving as judges,Utilizing N answers fro...</td>\n",
       "      <td>LLMs ascending to the role of a Judge,Challeng...</td>\n",
       "      <td>[LLMs, Judge, Evaluation challenges]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/posts/sahibpreetsingh...</td>\n",
       "      <td>ùóüùóîùó†ùóî is mastering üêë beneath a ...</td>\n",
       "      <td>[RAG application, RAPTOR, segmenting content]</td>\n",
       "      <td>Consider experimenting with algorithms like TS...</td>\n",
       "      <td>Developing a RAG application,Stumbled upon RAP...</td>\n",
       "      <td>[RAG application, RAPTOR, segmenting content]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/posts/jobanpreet-sing...</td>\n",
       "      <td>üé§üîé Unveiling the Essentials of...</td>\n",
       "      <td>[Whisper, Wav2Vec2.0, Log-mel Spectrogram]</td>\n",
       "      <td>Whisper has been trained on 680,000 hours of a...</td>\n",
       "      <td>Whisper model trained on refined annotated dat...</td>\n",
       "      <td>[Whisper, Wav2Vec2.0, Log-mel Spectrogram]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/posts/jobanpreet-sing...</td>\n",
       "      <td>Successfully Finished My Proje...</td>\n",
       "      <td>[English to Punjabi, encoder-decoder framework...</td>\n",
       "      <td>Successfully Finished My Project on Converting...</td>\n",
       "      <td>Sophisticated encoder-decoder framework with d...</td>\n",
       "      <td>[English to Punjabi, encoder-decoder framework...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  https://www.linkedin.com/posts/sahibpreetsingh...   \n",
       "1  https://www.linkedin.com/posts/sahibpreetsingh...   \n",
       "2  https://www.linkedin.com/posts/sahibpreetsingh...   \n",
       "3  https://www.linkedin.com/posts/jobanpreet-sing...   \n",
       "4  https://www.linkedin.com/posts/jobanpreet-sing...   \n",
       "\n",
       "                                    Paraphrased Post  \\\n",
       "0  Hello LLM Enthusiasts,\\nStarting a New Day wit...   \n",
       "1  Hello, ùóüùóüùó† Enthusiasts, Get Ready for an Adven...   \n",
       "2                  ùóüùóîùó†ùóî is mastering üêë beneath a ...   \n",
       "3                  üé§üîé Unveiling the Essentials of...   \n",
       "4                  Successfully Finished My Proje...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0                [Semantic Chunking, Retrieval, RAG]   \n",
       "1    [LLM Enthusiasts, Judge, LLM-generated answers]   \n",
       "2      [RAG application, RAPTOR, segmenting content]   \n",
       "3         [Whisper, Wav2Vec2.0, Log-mel Spectrogram]   \n",
       "4  [English to Punjabi, encoder-decoder framework...   \n",
       "\n",
       "                                          Take Aways  \\\n",
       "0  Chunking involves dividing a document into sma...   \n",
       "1  LLMs serving as judges,Utilizing N answers fro...   \n",
       "2  Consider experimenting with algorithms like TS...   \n",
       "3  Whisper has been trained on 680,000 hours of a...   \n",
       "4  Successfully Finished My Project on Converting...   \n",
       "\n",
       "                                          Highlights  \\\n",
       "0  How can we break down intricate user inquiries...   \n",
       "1  LLMs ascending to the role of a Judge,Challeng...   \n",
       "2  Developing a RAG application,Stumbled upon RAP...   \n",
       "3  Whisper model trained on refined annotated dat...   \n",
       "4  Sophisticated encoder-decoder framework with d...   \n",
       "\n",
       "                                GroundTruth Keywords  \n",
       "0                [Semantic Chunking, Retrieval, RAG]  \n",
       "1               [LLMs, Judge, Evaluation challenges]  \n",
       "2      [RAG application, RAPTOR, segmenting content]  \n",
       "3         [Whisper, Wav2Vec2.0, Log-mel Spectrogram]  \n",
       "4  [English to Punjabi, encoder-decoder framework...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e70aed4-6ddc-4215-8b18-8beeda3e705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59161a41-cbbc-4074-992b-623824162b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_similarity(list1, list2):\n",
    "    # Lowercase all keywords\n",
    "    list1_lower = [keyword.lower() for keyword in list1]\n",
    "    list2_lower = [keyword.lower() for keyword in list2]\n",
    "    \n",
    "    # Convert lists to sets\n",
    "    set1 = set(list1_lower)\n",
    "    set2 = set(list2_lower)\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    if len(union) == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    jaccard_similarity = len(intersection) / len(union)\n",
    "    \n",
    "    return jaccard_similarity\n",
    "similarities = []\n",
    "for index, row in df.iterrows():\n",
    "    jaccard_sim = calculate_jaccard_similarity(row['Keywords'], row['GroundTruth Keywords'])\n",
    "    similarities.append(jaccard_sim)\n",
    "\n",
    "# Add similarity scores to dataframe\n",
    "df['jaccard_similarity'] = similarities\n",
    "\n",
    "\n",
    "average_similarity = df['jaccard_similarity'].mean()\n",
    "df.loc['Average_jaccard_similarity'] = pd.Series({'jaccard_similarity': average_similarity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2956eede-bac4-422b-9852-ba13a093061b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Paraphrased Post</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Take Aways</th>\n",
       "      <th>Highlights</th>\n",
       "      <th>GroundTruth Keywords</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/posts/sahibpreetsingh...</td>\n",
       "      <td>Hello LLM Enthusiasts,\\nStarting a New Day wit...</td>\n",
       "      <td>[Semantic Chunking, Retrieval, RAG]</td>\n",
       "      <td>Chunking involves dividing a document into sma...</td>\n",
       "      <td>How can we break down intricate user inquiries...</td>\n",
       "      <td>[Semantic Chunking, Retrieval, RAG]</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/posts/sahibpreetsingh...</td>\n",
       "      <td>Hello, ùóüùóüùó† Enthusiasts, Get Ready for an Adven...</td>\n",
       "      <td>[LLM Enthusiasts, Judge, LLM-generated answers]</td>\n",
       "      <td>LLMs serving as judges,Utilizing N answers fro...</td>\n",
       "      <td>LLMs ascending to the role of a Judge,Challeng...</td>\n",
       "      <td>[LLMs, Judge, Evaluation challenges]</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/posts/sahibpreetsingh...</td>\n",
       "      <td>ùóüùóîùó†ùóî is mastering üêë beneath a ...</td>\n",
       "      <td>[RAG application, RAPTOR, segmenting content]</td>\n",
       "      <td>Consider experimenting with algorithms like TS...</td>\n",
       "      <td>Developing a RAG application,Stumbled upon RAP...</td>\n",
       "      <td>[RAG application, RAPTOR, segmenting content]</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/posts/jobanpreet-sing...</td>\n",
       "      <td>üé§üîé Unveiling the Essentials of...</td>\n",
       "      <td>[Whisper, Wav2Vec2.0, Log-mel Spectrogram]</td>\n",
       "      <td>Whisper has been trained on 680,000 hours of a...</td>\n",
       "      <td>Whisper model trained on refined annotated dat...</td>\n",
       "      <td>[Whisper, Wav2Vec2.0, Log-mel Spectrogram]</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/posts/jobanpreet-sing...</td>\n",
       "      <td>Successfully Finished My Proje...</td>\n",
       "      <td>[English to Punjabi, encoder-decoder framework...</td>\n",
       "      <td>Successfully Finished My Project on Converting...</td>\n",
       "      <td>Sophisticated encoder-decoder framework with d...</td>\n",
       "      <td>[English to Punjabi, encoder-decoder framework...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.linkedin.com/posts/mohamedsalama1_...</td>\n",
       "      <td>Introducing ReFT: Revolutioniz...</td>\n",
       "      <td>[ReFT, LLM Fine-Tuning, Large Language Models]</td>\n",
       "      <td>ReFT enhances LLMs by applying a warm-up phase...</td>\n",
       "      <td>ReFT is a groundbreaking method to boost the l...</td>\n",
       "      <td>[ReFT, LLM Fine-Tuning, Large Language Models]</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.linkedin.com/posts/bavalpreet-sing...</td>\n",
       "      <td>#Google has recently unveiled #Gemma, a ground...</td>\n",
       "      <td>[Gemma, models, technology]</td>\n",
       "      <td>Gemma is available in two models: 2B and 7B,Ge...</td>\n",
       "      <td>Model Variants: Gemma is available in two mode...</td>\n",
       "      <td>[Gemma, features of Gemma, Gemma‚Äôs architecture ]</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.linkedin.com/posts/vasanthengineer...</td>\n",
       "      <td>Grok - 1, the newest MOE model boasting a 31B ...</td>\n",
       "      <td>[Grok - 1, MOE model, 31B parameter size]</td>\n",
       "      <td>A 314B parameter MOE model with 86B operationa...</td>\n",
       "      <td>A 314B parameter MOE model with 86B operationa...</td>\n",
       "      <td>[Grok - 1, MOE model, 31B parameter size]</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.linkedin.com/posts/vasanthengineer...</td>\n",
       "      <td>Curious about linking your Large Language Mode...</td>\n",
       "      <td>[Large Language Models, LLMs, CSV]</td>\n",
       "      <td>Convert a CSV file into an SQL schema,Present ...</td>\n",
       "      <td>Utilizing the Groq Inference Engine to operate...</td>\n",
       "      <td>[Large Language Models, LLMs, CSV]</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.linkedin.com/posts/vasanthengineer...</td>\n",
       "      <td>Following the unveiling of the groundbreaking ...</td>\n",
       "      <td>[Devin AI, Cognition, job threat]</td>\n",
       "      <td>Devin AI unveiling by Cognition,Understanding ...</td>\n",
       "      <td>Devin AI unveiling by Cognition,Comprehensive ...</td>\n",
       "      <td>[Devin AI, Cognition, job threat]</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average_jaccard_similarity</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         Link  \\\n",
       "0                           https://www.linkedin.com/posts/sahibpreetsingh...   \n",
       "1                           https://www.linkedin.com/posts/sahibpreetsingh...   \n",
       "2                           https://www.linkedin.com/posts/sahibpreetsingh...   \n",
       "3                           https://www.linkedin.com/posts/jobanpreet-sing...   \n",
       "4                           https://www.linkedin.com/posts/jobanpreet-sing...   \n",
       "5                           https://www.linkedin.com/posts/mohamedsalama1_...   \n",
       "6                           https://www.linkedin.com/posts/bavalpreet-sing...   \n",
       "7                           https://www.linkedin.com/posts/vasanthengineer...   \n",
       "8                           https://www.linkedin.com/posts/vasanthengineer...   \n",
       "9                           https://www.linkedin.com/posts/vasanthengineer...   \n",
       "Average_jaccard_similarity                                                NaN   \n",
       "\n",
       "                                                             Paraphrased Post  \\\n",
       "0                           Hello LLM Enthusiasts,\\nStarting a New Day wit...   \n",
       "1                           Hello, ùóüùóüùó† Enthusiasts, Get Ready for an Adven...   \n",
       "2                                           ùóüùóîùó†ùóî is mastering üêë beneath a ...   \n",
       "3                                           üé§üîé Unveiling the Essentials of...   \n",
       "4                                           Successfully Finished My Proje...   \n",
       "5                                           Introducing ReFT: Revolutioniz...   \n",
       "6                           #Google has recently unveiled #Gemma, a ground...   \n",
       "7                           Grok - 1, the newest MOE model boasting a 31B ...   \n",
       "8                           Curious about linking your Large Language Mode...   \n",
       "9                           Following the unveiling of the groundbreaking ...   \n",
       "Average_jaccard_similarity                                                NaN   \n",
       "\n",
       "                                                                     Keywords  \\\n",
       "0                                         [Semantic Chunking, Retrieval, RAG]   \n",
       "1                             [LLM Enthusiasts, Judge, LLM-generated answers]   \n",
       "2                               [RAG application, RAPTOR, segmenting content]   \n",
       "3                                  [Whisper, Wav2Vec2.0, Log-mel Spectrogram]   \n",
       "4                           [English to Punjabi, encoder-decoder framework...   \n",
       "5                              [ReFT, LLM Fine-Tuning, Large Language Models]   \n",
       "6                                                 [Gemma, models, technology]   \n",
       "7                                   [Grok - 1, MOE model, 31B parameter size]   \n",
       "8                                          [Large Language Models, LLMs, CSV]   \n",
       "9                                           [Devin AI, Cognition, job threat]   \n",
       "Average_jaccard_similarity                                                NaN   \n",
       "\n",
       "                                                                   Take Aways  \\\n",
       "0                           Chunking involves dividing a document into sma...   \n",
       "1                           LLMs serving as judges,Utilizing N answers fro...   \n",
       "2                           Consider experimenting with algorithms like TS...   \n",
       "3                           Whisper has been trained on 680,000 hours of a...   \n",
       "4                           Successfully Finished My Project on Converting...   \n",
       "5                           ReFT enhances LLMs by applying a warm-up phase...   \n",
       "6                           Gemma is available in two models: 2B and 7B,Ge...   \n",
       "7                           A 314B parameter MOE model with 86B operationa...   \n",
       "8                           Convert a CSV file into an SQL schema,Present ...   \n",
       "9                           Devin AI unveiling by Cognition,Understanding ...   \n",
       "Average_jaccard_similarity                                                NaN   \n",
       "\n",
       "                                                                   Highlights  \\\n",
       "0                           How can we break down intricate user inquiries...   \n",
       "1                           LLMs ascending to the role of a Judge,Challeng...   \n",
       "2                           Developing a RAG application,Stumbled upon RAP...   \n",
       "3                           Whisper model trained on refined annotated dat...   \n",
       "4                           Sophisticated encoder-decoder framework with d...   \n",
       "5                           ReFT is a groundbreaking method to boost the l...   \n",
       "6                           Model Variants: Gemma is available in two mode...   \n",
       "7                           A 314B parameter MOE model with 86B operationa...   \n",
       "8                           Utilizing the Groq Inference Engine to operate...   \n",
       "9                           Devin AI unveiling by Cognition,Comprehensive ...   \n",
       "Average_jaccard_similarity                                                NaN   \n",
       "\n",
       "                                                         GroundTruth Keywords  \\\n",
       "0                                         [Semantic Chunking, Retrieval, RAG]   \n",
       "1                                        [LLMs, Judge, Evaluation challenges]   \n",
       "2                               [RAG application, RAPTOR, segmenting content]   \n",
       "3                                  [Whisper, Wav2Vec2.0, Log-mel Spectrogram]   \n",
       "4                           [English to Punjabi, encoder-decoder framework...   \n",
       "5                              [ReFT, LLM Fine-Tuning, Large Language Models]   \n",
       "6                           [Gemma, features of Gemma, Gemma‚Äôs architecture ]   \n",
       "7                                   [Grok - 1, MOE model, 31B parameter size]   \n",
       "8                                          [Large Language Models, LLMs, CSV]   \n",
       "9                                           [Devin AI, Cognition, job threat]   \n",
       "Average_jaccard_similarity                                                NaN   \n",
       "\n",
       "                            jaccard_similarity  \n",
       "0                                         1.00  \n",
       "1                                         0.20  \n",
       "2                                         1.00  \n",
       "3                                         1.00  \n",
       "4                                         0.50  \n",
       "5                                         1.00  \n",
       "6                                         0.20  \n",
       "7                                         1.00  \n",
       "8                                         1.00  \n",
       "9                                         1.00  \n",
       "Average_jaccard_similarity                0.79  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de872654-c36c-4d15-852b-c68a871be1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65733d14-aff1-431e-9792-26cc0e35eb28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
